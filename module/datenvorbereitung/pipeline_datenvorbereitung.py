import os
import sys

# === Zentrale Konfiguration importieren ===
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..')))
import config

# Projektpfade initialisieren
config.init_project_paths()

# === Import der Datenvorbereitung-Module ===
from . import (
    DatenEinlesen,
    SpaltennamenKorrigieren,
    DatumFormatieren,
    TemperaturUndDatumExtrahieren,
    ZeitreiheAb1880,
    NaNPruefen,
    DatentypenPruefen,
    DuplikatePruefen,
    BereinigteDatenSpeichern
)

def process_single_city(city, input_path, output_path, sep=";", decimal=","):
    """
    Verarbeitet die Daten einer einzelnen Stadt durch die komplette Pipeline.

    Parameters:
    city: str - Name der Stadt
    input_path: str - Pfad zur Eingabedatei
    output_path: str - Pfad zur Ausgabedatei
    sep: str - CSV-Separator
    decimal: str - Dezimaltrennzeichen

    Returns:
    bool - True wenn erfolgreich, False bei Fehler
    """
    print(f"\nğŸ“ Stadt: {city}")
    print(f"   ğŸ“‚ Eingabe: {os.path.basename(input_path)}")
    print(f"   ğŸ’¾ Ausgabe: {os.path.basename(output_path)}")

    try:
        # 1. Daten einlesen
        print("   ğŸ”„ Schritt 1: Daten einlesen...")
        df = DatenEinlesen(input_path, sep=sep, decimal=decimal)

        if df is None:
            print(f"   âŒ Fehler beim Einlesen der Daten. Ãœberspringe {city}.")
            return False

        original_rows = len(df)
        print(f"   âœ… {original_rows} DatensÃ¤tze eingelesen")

        # 2. Spaltennamen korrigieren
        print("   ğŸ”„ Schritt 2: Spaltennamen korrigieren...")
        df = SpaltennamenKorrigieren(df)
        print("   âœ… Spaltennamen korrigiert")

        # 3. Datum formatieren
        print("   ğŸ”„ Schritt 3: Datum formatieren...")
        df = DatumFormatieren(df)
        print("   âœ… Datum formatiert")

        # 4. Temperatur und Datum extrahieren
        print("   ğŸ”„ Schritt 4: Temperatur und Datum extrahieren...")
        df = TemperaturUndDatumExtrahieren(df)
        print("   âœ… Nur relevante Spalten extrahiert")

        # 5. Zeitreihe ab 1880 filtern
        print("   ğŸ”„ Schritt 5: Daten ab 1880 filtern...")
        df = ZeitreiheAb1880(df)
        filtered_rows = len(df)
        print(f"   âœ… Daten gefiltert ({original_rows} â†’ {filtered_rows} DatensÃ¤tze)")

        # 6. NaN-Werte prÃ¼fen
        print("   ğŸ”„ Schritt 6: NaN-Werte prÃ¼fen...")
        df = NaNPruefen(df)
        print("   âœ… NaN-PrÃ¼fung abgeschlossen")

        # 7. Datentypen prÃ¼fen
        print("   ğŸ”„ Schritt 7: Datentypen prÃ¼fen...")
        DatentypenPruefen(df)
        print("   âœ… Datentypen geprÃ¼ft")

        # 8. Duplikate prÃ¼fen
        print("   ğŸ”„ Schritt 8: Duplikate prÃ¼fen...")
        DuplikatePruefen(df)
        print("   âœ… Duplikate geprÃ¼ft")

        # 9. Daten speichern
        print("   ğŸ”„ Schritt 9: Bereinigte Daten speichern...")
        BereinigteDatenSpeichern(df, output_path)
        final_rows = len(df)
        print(f"   âœ… Daten gespeichert ({final_rows} DatensÃ¤tze)")

        print(f"   ğŸ¯ {city} erfolgreich verarbeitet!")
        print("\n" + "="*80)
        return True

    except Exception as e:
        print(f"   âŒ Fehler bei {city}: {e}")
        return False

def run_complete_preprocessing():
    """
    FÃ¼hrt die komplette Datenvorbereitungspipeline fÃ¼r alle StÃ¤dte durch.
    """
    print("ğŸš€ Starte komplette Datenvorbereitungspipeline...")
    print(f"ğŸ“ Projektverzeichnis: {config.PROJECT_ROOT}")
    print(f"ğŸ™ï¸ StÃ¤dte: {', '.join(config.CITIES)}")
    print("\n" + "="*80)

    success_count = 0

    # Alle StÃ¤dte verarbeiten
    for city in config.CITIES:
        input_path = config.CITY_PATHS_ORIGINAL[city]
        output_path = config.CITY_PATHS_CLEAN[city]

        # Stelle sicher, dass das Ausgabeverzeichnis existiert
        os.makedirs(os.path.dirname(output_path), exist_ok=True)

        # Stadt verarbeiten
        if process_single_city(city, input_path, output_path):
            success_count += 1

    # Zusammenfassung
    if success_count == len(config.CITIES):
        print("ğŸ‰ DATENVORBEREITUNGSPIPELINE ERFOLGREICH ABGESCHLOSSEN! ğŸ‰")
    else:
        print(f"âš ï¸ DATENVORBEREITUNGSPIPELINE BEENDET - {success_count}/{len(config.CITIES)} STÃ„DTE ERFOLGREICH")

    print(f"ğŸ“ Bereinigte Daten befinden sich in: {os.path.join(config.PROJECT_ROOT, 'daten', 'bereinigte-daten')}")
    print("="*80)

    return success_count == len(config.CITIES)

def run_single_preprocessing(city):
    """
    FÃ¼hrt die Datenvorbereitungspipeline fÃ¼r eine spezifische Stadt durch.

    Parameters:
    city: str - Name der Stadt ('abakan', 'berlin', 'angeles')

    Returns:
    bool - True wenn erfolgreich, False bei Fehler
    """
    if city not in config.CITIES:
        print(f"âŒ Unbekannte Stadt: {city}")
        print(f"VerfÃ¼gbare StÃ¤dte: {config.CITIES}")
        return False

    print(f"ğŸš€ Starte Datenvorbereitung fÃ¼r {city}...")
    print("="*60)

    input_path = config.CITY_PATHS_ORIGINAL[city]
    output_path = config.CITY_PATHS_CLEAN[city]

    # Stelle sicher, dass das Ausgabeverzeichnis existiert
    os.makedirs(os.path.dirname(output_path), exist_ok=True)

    # Stadt verarbeiten
    success = process_single_city(city, input_path, output_path)

    print("="*60)
    if success:
        print(f"âœ… Datenvorbereitung fÃ¼r {city} erfolgreich abgeschlossen")
    else:
        print(f"âŒ Datenvorbereitung fÃ¼r {city} fehlgeschlagen")

    return success

def main():
    """
    Hauptfunktion fÃ¼r die Datenvorbereitung - fÃ¼hrt die komplette Pipeline durch
    """
    run_complete_preprocessing()

# === HauptausfÃ¼hrung ===
if __name__ == "__main__":
    main()